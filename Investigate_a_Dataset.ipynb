{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Finding Correlations among Unrelated Variables\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploring the Data</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## I) Introduction\n",
    "\n",
    "**Broad question:** How do total forest area and frequency of natural disasters shape a country's obesity rates and murder rates?\n",
    "\n",
    "> I picked these factors which seem to be unrelated--geography & frequency of natural disasters, to rates of obesity murder, to formulate new interesting questions and uncover unexpected patterns. I also wanted to approach this project through an experimental and free-for-all lens, just to see if I can make any fun or comical conclusions from the giving unrelated datasets. To narrow down my focus, I picked subcategory of [TK] for geography, [TK] for education and [TK] to encompass murder rates. I received all of my data through GapMinder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "# II) Data Wrangling\n",
    "\n",
    "## A) Gathering Data\n",
    "\n",
    "#### Natural Disasters\n",
    "> I took [TK list dataset names here], each depicting the number of deaths of their respective natural disaster. To combine those datasets, I generated a new CSV file named `natural_disaster_deaths.csv`, which depicts the sum of deaths by natural disaster per year for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all DataFrames for natural disasters\n",
    "filepath_disasters = './data/natural_disasters/'\n",
    "\n",
    "#assign country names as primary indexes\n",
    "df_drought = pd.read_csv(filepath_disasters + 'indicator_drought_killed.csv', index_col = 'Drought killed')\n",
    "df_earthquake = pd.read_csv(filepath_disasters + 'indicator_earthquake_killed.csv', index_col = 'Earthquake killed')\n",
    "df_epidemic = pd.read_csv(filepath_disasters + 'indicator_epidemic_killed.csv', index_col = 'Epidemic killed')\n",
    "df_flood = pd.read_csv(filepath_disasters + 'indicator_flood_killed.csv', index_col = 'Flood killed')\n",
    "df_storm = pd.read_csv(filepath_disasters + 'indicator_storm_killed.csv', index_col = 'Storm killed')\n",
    "df_tsunami = pd.read_csv(filepath_disasters + 'indicator_tsunami_killed.csv', index_col = 'Tsunami killed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all DataFrames in a dictionary for iteration\n",
    "dict_dfs = {'drought killed' : df_drought,\n",
    "            'earthquake killed' : df_earthquake,\n",
    "            'epidemic killed' : df_epidemic,\n",
    "            'flood killed' : df_flood,\n",
    "            'storm killed' : df_storm,\n",
    "            'tsunami killed' : df_tsunami\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Forest Area\n",
    "> I am focusing on total natural forest land per country, and so I will exclude factors that indicate if said forest land is reserved for agricultural production.\n",
    "\n",
    "> From GapMinder, forest area is described as ‘land under natural or planted stands of trees of at least 5 meters in situ, whether productive or not, and excludes tree stands in agricultural production systems (for example, in fruit plantations and agroforestry systems) and trees in urban parks and gardens.' The dataset `forest_area_sq_km.csv` keeps track of the total forest area from 1990 to 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>13500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>7890.0</td>\n",
       "      <td>7870.0</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>7790.0</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7730.0</td>\n",
       "      <td>7710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>7790.0</td>\n",
       "      <td>7780.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>7740.0</td>\n",
       "      <td>7730.0</td>\n",
       "      <td>7720.0</td>\n",
       "      <td>7720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>16700.0</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>16300.0</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>16100.0</td>\n",
       "      <td>16100.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16100.0</td>\n",
       "      <td>16900.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18400.0</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>19400.0</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>19600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>610000.0</td>\n",
       "      <td>609000.0</td>\n",
       "      <td>607000.0</td>\n",
       "      <td>606000.0</td>\n",
       "      <td>605000.0</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>602000.0</td>\n",
       "      <td>601000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>599000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>589000.0</td>\n",
       "      <td>587000.0</td>\n",
       "      <td>586000.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>584000.0</td>\n",
       "      <td>582000.0</td>\n",
       "      <td>581000.0</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>579000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1990      1991      1992      1993      1994      1995  \\\n",
       "country                                                                   \n",
       "Afghanistan   13500.0   13500.0   13500.0   13500.0   13500.0   13500.0   \n",
       "Albania        7890.0    7870.0    7850.0    7830.0    7810.0    7790.0   \n",
       "Algeria       16700.0   16600.0   16500.0   16400.0   16300.0   16200.0   \n",
       "Andorra         160.0     160.0     160.0     160.0     160.0     160.0   \n",
       "Angola       610000.0  609000.0  607000.0  606000.0  605000.0  604000.0   \n",
       "\n",
       "                 1996      1997      1998      1999  ...      2006      2007  \\\n",
       "country                                              ...                       \n",
       "Afghanistan   13500.0   13500.0   13500.0   13500.0  ...   13500.0   13500.0   \n",
       "Albania        7770.0    7750.0    7730.0    7710.0  ...    7810.0    7800.0   \n",
       "Algeria       16100.0   16100.0   16000.0   15900.0  ...   16100.0   16900.0   \n",
       "Andorra         160.0     160.0     160.0     160.0  ...     160.0     160.0   \n",
       "Angola       602000.0  601000.0  600000.0  599000.0  ...  590000.0  589000.0   \n",
       "\n",
       "                 2008      2009      2010      2011      2012      2013  \\\n",
       "country                                                                   \n",
       "Afghanistan   13500.0   13500.0   13500.0   13500.0   13500.0   13500.0   \n",
       "Albania        7790.0    7780.0    7760.0    7750.0    7740.0    7730.0   \n",
       "Algeria       17700.0   18400.0   19200.0   19300.0   19300.0   19400.0   \n",
       "Andorra         160.0     160.0     160.0     160.0     160.0     160.0   \n",
       "Angola       587000.0  586000.0  585000.0  584000.0  582000.0  581000.0   \n",
       "\n",
       "                 2014      2015  \n",
       "country                          \n",
       "Afghanistan   13500.0   13500.0  \n",
       "Albania        7720.0    7720.0  \n",
       "Algeria       19500.0   19600.0  \n",
       "Andorra         160.0     160.0  \n",
       "Angola       580000.0  579000.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forest = pd.read_csv('./data/forest_area_sq_km.csv', index_col='country')\n",
    "df_forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obesity Rates\n",
    "> GapMinder provided the age standardized mean for BMI, dividing it into BMI values for men and women. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmi_male = pd.read_csv('./data/bmi_rates/bmi_male.csv', index_col='Country')\n",
    "df_bmi_female = pd.read_csv('./data/bmi_rates/bmi_female.csv', index_col='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>...</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>21.48678</td>\n",
       "      <td>21.46552</td>\n",
       "      <td>21.45145</td>\n",
       "      <td>21.43822</td>\n",
       "      <td>21.42734</td>\n",
       "      <td>21.41222</td>\n",
       "      <td>21.40132</td>\n",
       "      <td>21.37679</td>\n",
       "      <td>21.34018</td>\n",
       "      <td>21.29845</td>\n",
       "      <td>...</td>\n",
       "      <td>20.75469</td>\n",
       "      <td>20.69521</td>\n",
       "      <td>20.62643</td>\n",
       "      <td>20.59848</td>\n",
       "      <td>20.58706</td>\n",
       "      <td>20.57759</td>\n",
       "      <td>20.58084</td>\n",
       "      <td>20.58749</td>\n",
       "      <td>20.60246</td>\n",
       "      <td>20.62058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>25.22533</td>\n",
       "      <td>25.23981</td>\n",
       "      <td>25.25636</td>\n",
       "      <td>25.27176</td>\n",
       "      <td>25.27901</td>\n",
       "      <td>25.28669</td>\n",
       "      <td>25.29451</td>\n",
       "      <td>25.30217</td>\n",
       "      <td>25.30450</td>\n",
       "      <td>25.31944</td>\n",
       "      <td>...</td>\n",
       "      <td>25.46555</td>\n",
       "      <td>25.55835</td>\n",
       "      <td>25.66701</td>\n",
       "      <td>25.77167</td>\n",
       "      <td>25.87274</td>\n",
       "      <td>25.98136</td>\n",
       "      <td>26.08939</td>\n",
       "      <td>26.20867</td>\n",
       "      <td>26.32753</td>\n",
       "      <td>26.44657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>22.25703</td>\n",
       "      <td>22.34745</td>\n",
       "      <td>22.43647</td>\n",
       "      <td>22.52105</td>\n",
       "      <td>22.60633</td>\n",
       "      <td>22.69501</td>\n",
       "      <td>22.76979</td>\n",
       "      <td>22.84096</td>\n",
       "      <td>22.90644</td>\n",
       "      <td>22.97931</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69486</td>\n",
       "      <td>23.77659</td>\n",
       "      <td>23.86256</td>\n",
       "      <td>23.95294</td>\n",
       "      <td>24.05243</td>\n",
       "      <td>24.15957</td>\n",
       "      <td>24.27001</td>\n",
       "      <td>24.38270</td>\n",
       "      <td>24.48846</td>\n",
       "      <td>24.59620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>25.66652</td>\n",
       "      <td>25.70868</td>\n",
       "      <td>25.74681</td>\n",
       "      <td>25.78250</td>\n",
       "      <td>25.81874</td>\n",
       "      <td>25.85236</td>\n",
       "      <td>25.89089</td>\n",
       "      <td>25.93414</td>\n",
       "      <td>25.98477</td>\n",
       "      <td>26.04450</td>\n",
       "      <td>...</td>\n",
       "      <td>26.75078</td>\n",
       "      <td>26.83179</td>\n",
       "      <td>26.92373</td>\n",
       "      <td>27.02525</td>\n",
       "      <td>27.12481</td>\n",
       "      <td>27.23107</td>\n",
       "      <td>27.32827</td>\n",
       "      <td>27.43588</td>\n",
       "      <td>27.53363</td>\n",
       "      <td>27.63048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>20.94876</td>\n",
       "      <td>20.94371</td>\n",
       "      <td>20.93754</td>\n",
       "      <td>20.93187</td>\n",
       "      <td>20.93569</td>\n",
       "      <td>20.94857</td>\n",
       "      <td>20.96030</td>\n",
       "      <td>20.98025</td>\n",
       "      <td>21.01375</td>\n",
       "      <td>21.05269</td>\n",
       "      <td>...</td>\n",
       "      <td>21.31954</td>\n",
       "      <td>21.37480</td>\n",
       "      <td>21.43664</td>\n",
       "      <td>21.51765</td>\n",
       "      <td>21.59924</td>\n",
       "      <td>21.69218</td>\n",
       "      <td>21.80564</td>\n",
       "      <td>21.93881</td>\n",
       "      <td>22.08962</td>\n",
       "      <td>22.25083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1980      1981      1982      1983      1984      1985  \\\n",
       "Country                                                                   \n",
       "Afghanistan  21.48678  21.46552  21.45145  21.43822  21.42734  21.41222   \n",
       "Albania      25.22533  25.23981  25.25636  25.27176  25.27901  25.28669   \n",
       "Algeria      22.25703  22.34745  22.43647  22.52105  22.60633  22.69501   \n",
       "Andorra      25.66652  25.70868  25.74681  25.78250  25.81874  25.85236   \n",
       "Angola       20.94876  20.94371  20.93754  20.93187  20.93569  20.94857   \n",
       "\n",
       "                 1986      1987      1988      1989  ...      1999      2000  \\\n",
       "Country                                              ...                       \n",
       "Afghanistan  21.40132  21.37679  21.34018  21.29845  ...  20.75469  20.69521   \n",
       "Albania      25.29451  25.30217  25.30450  25.31944  ...  25.46555  25.55835   \n",
       "Algeria      22.76979  22.84096  22.90644  22.97931  ...  23.69486  23.77659   \n",
       "Andorra      25.89089  25.93414  25.98477  26.04450  ...  26.75078  26.83179   \n",
       "Angola       20.96030  20.98025  21.01375  21.05269  ...  21.31954  21.37480   \n",
       "\n",
       "                 2001      2002      2003      2004      2005      2006  \\\n",
       "Country                                                                   \n",
       "Afghanistan  20.62643  20.59848  20.58706  20.57759  20.58084  20.58749   \n",
       "Albania      25.66701  25.77167  25.87274  25.98136  26.08939  26.20867   \n",
       "Algeria      23.86256  23.95294  24.05243  24.15957  24.27001  24.38270   \n",
       "Andorra      26.92373  27.02525  27.12481  27.23107  27.32827  27.43588   \n",
       "Angola       21.43664  21.51765  21.59924  21.69218  21.80564  21.93881   \n",
       "\n",
       "                 2007      2008  \n",
       "Country                          \n",
       "Afghanistan  20.60246  20.62058  \n",
       "Albania      26.32753  26.44657  \n",
       "Algeria      24.48846  24.59620  \n",
       "Andorra      27.53363  27.63048  \n",
       "Angola       22.08962  22.25083  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bmi_male.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Murder Rates\n",
    "> Encompasses number of murders per 100,000 people, accounting for all ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder = pd.read_csv('./data/homicide_rates.csv', index_col='Murder per 100,000, age adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>...</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Murder per 100,000, age adjusted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.650731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.837318</td>\n",
       "      <td>3.837318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.972975</td>\n",
       "      <td>8.115989</td>\n",
       "      <td>6.681117</td>\n",
       "      <td>7.326701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.100290</td>\n",
       "      <td>14.410269</td>\n",
       "      <td>9.806334</td>\n",
       "      <td>4.389205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726513</td>\n",
       "      <td>0.726513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.057260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.206188</td>\n",
       "      <td>48.206188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  1950  1951  1952  1953  1954  1955  1956  \\\n",
       "Murder per 100,000, age adjusted                                             \n",
       "Afghanistan                        NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "Albania                            NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "Algeria                            NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "Andorra                            NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "Angola                             NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                                  1957  1958  1959  ...  1996  1997  1998  \\\n",
       "Murder per 100,000, age adjusted                    ...                     \n",
       "Afghanistan                        NaN   NaN   NaN  ...   NaN   NaN   NaN   \n",
       "Albania                            NaN   NaN   NaN  ...   NaN   NaN   NaN   \n",
       "Algeria                            NaN   NaN   NaN  ...   NaN   NaN   NaN   \n",
       "Andorra                            NaN   NaN   NaN  ...   NaN   NaN   NaN   \n",
       "Angola                             NaN   NaN   NaN  ...   NaN   NaN   NaN   \n",
       "\n",
       "                                  1999  2000  2001       2002       2003  \\\n",
       "Murder per 100,000, age adjusted                                           \n",
       "Afghanistan                        NaN   NaN   NaN   4.650731        NaN   \n",
       "Albania                            NaN   NaN   NaN   5.972975   8.115989   \n",
       "Algeria                            NaN   NaN   NaN  13.100290  14.410269   \n",
       "Andorra                            NaN   NaN   NaN   0.767467        NaN   \n",
       "Angola                             NaN   NaN   NaN  51.057260        NaN   \n",
       "\n",
       "                                       2004       2005  \n",
       "Murder per 100,000, age adjusted                        \n",
       "Afghanistan                        3.837318   3.837318  \n",
       "Albania                            6.681117   7.326701  \n",
       "Algeria                            9.806334   4.389205  \n",
       "Andorra                            0.726513   0.726513  \n",
       "Angola                            48.206188  48.206188  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_murder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Data Cleaning\n",
    "\n",
    "### Natural Disasters\n",
    "> To account for all natural disasters that occurred in each country, my goal is to generate a new CSV file where each cell contains the sum of all the natural disaster DataFrames.\n",
    "\n",
    "Let's examine the columns of each natural disaster DataFrame. There are 195 total countries in the world, so I am expecting there to be at most 195 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drought killed (128, 39)\n",
      "Earthquake killed (97, 39)\n",
      "Epidemic killed (143, 38)\n",
      "Flood killed (182, 39)\n",
      "Storm killed (181, 39)\n",
      "Tsunami killed (18, 15)\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    #display (row, column) per DataFrame\n",
    "    print(df.index.name, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It can be seen that the DataFrame for tsunamis is the least reported out of all the other natural disasters (accounting for only 18 countries), while the most documented natural disaster is floods, at 181 countries. This adds more ambiguity as to how we should generate our final CSV file accounting for all natural disasters in all countries.\n",
    "\n",
    "> Now there are two possibilities for approaching this:\n",
    "\n",
    "Approach 1) The missing countries means that no natural disasters occurred in them, and so it was not necessary to include them in their respective DataFrames.\n",
    "\n",
    "> Therefore **it is safe to set the values of the missing countries to 0 and generate the final CSV as a sum of all the DataFrames.**\n",
    "\n",
    "Approach 2) We do not know if any natural disasters occurred in the missing countries.\n",
    "\n",
    "> Therefore **we should focus only the countries in common who have no missing values.**\n",
    "\n",
    "I ended up picking **Approach 2** because as can be seen in the above df_drought DataFrame, there are values for 0 in countries and years where no earthquakes happened. The best conclusion I can come for the missing indexed countries is that there has been no data recorded for them, and therefore I cannot assume whether or not earthquakes ever occurred in the missing countries. This logic extends to the rest of the DataFrames for the natural disasters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *DROP NULLS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# NaN in drought killed : 0\n",
      "# NaN in earthquake killed : 0\n",
      "# NaN in epidemic killed : 0\n",
      "# NaN in flood killed : 0\n",
      "# NaN in storm killed : 0\n",
      "# NaN in tsunami killed : 248\n"
     ]
    }
   ],
   "source": [
    "#Display number of NaN values in each dataset\n",
    "for key, df in dict_dfs.items():\n",
    "    #display (row, column) per DataFrame\n",
    "    print('# NaN in {} : {}'.format(key, df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only the tsunami dataset has null values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nulls from tsunami dataset\n",
    "df_tsunami.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm changes\n",
    "df_tsunami.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But hold up!**\n",
    "> Before we move on, let's check the first few rows of the tsunami data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tsunami killed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [1979, 1980, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007]\n",
       "Index: []"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many values exist in the tsunami data set\n",
    "print(df_tsunami.count().sum())\n",
    "\n",
    "df_tsunami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results show that only the last DataFrame for tsunamis contains null values. \n",
    "\n",
    "> The tsunami dataset is completely empty, which means we'll have to discard it. This makes me come to the conclusion that ***every single row in the data set contained a null value, which means that after dropping all the null values, the dataset became completely empty.***\n",
    "\n",
    "> I know it's painful to have to discard an entire DataFrame, but at least that is better than incorporating largely unreliable data into our final analysis.\n",
    "\n",
    "Before moving on, let's update our NumPy array to exclude the tsunami dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop tsunami dataset\n",
    "dict_dfs.pop('tsunami killed', None)\n",
    "\n",
    "#check changes\n",
    "len(dict_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 5 DataFrames in the dictionary instead of 6, so we can move on.\n",
    "\n",
    "### *Dedupe Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "21\n",
      "21\n",
      "30\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "#Check for number of duplicate data per row\n",
    "for key, df in dict_dfs.items():\n",
    "    print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But wait, we don't want to drop duplicate data just yet. As we know, many of the DataFrames are populated with rows containing only 0's. Before we drop duplicate rows, let's make sure that they are all actually **zeroes** and not just rows populated with the same repeating values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Display all duplicated rows in each DataFrame\n",
    "for key, df in dict_dfs.items():\n",
    "    #return True if the dataset contains a value that's not 0\n",
    "    print(df[df.duplicated(keep=False)].any().any())\n",
    "    \n",
    "    \n",
    "# print(df[1][df[1].duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some of the DataFrames have values that are greater than 0. But I've come to realize I don't necessarily care about the duplicate values themselves. The real question is: **are they repeating countries?** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check if any of the DataFrames have duplicate index 'country'\n",
    "for df in np.ndenumerate(dfs_nd_dropped):\n",
    "    #return True if the dataset contains a repeating country\n",
    "    print(df[1].index.duplicated().sum().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> None of the DataFrames have repeating countries for indexes. This is good news! Our data has turned out to be much more reliable than expected.\n",
    "\n",
    "Now we can decide to drop the duplicated rows or not, but I have **ultimately decided not to.** This is an exceptional case. Dropping the rows could harm our data reliability in the end, because dropping duplicates means we would be getting rid of natural disaster scores for entire countries in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Index to 'Country' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    #rename moved column name to 'country'\n",
    "    new_columns = np.insert(df.columns.values, 0, 'country', axis = 0)\n",
    "    df.reset_index(inplace = True)\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    #verify that all dfs have column named 'country'\n",
    "    print(np.any(df.columns.values == 'country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FIX DATA TYPES*\n",
    "\n",
    "Counting the number of natural disaster occurrences means handling **discrete variables**, so it would make the most sense to convert all of the values in every DataFrame to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('int64')]\n",
      "[dtype('int64')]\n",
      "[dtype('int64')]\n",
      "[dtype('int64')]\n",
      "[dtype('int64')]\n"
     ]
    }
   ],
   "source": [
    "#Display data types of each DataFrame\n",
    "for df in np.ndenumerate(dfs_nd_dropped):\n",
    "    print(np.unique(df[1].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns contain only integer values, so we do not have to perform any data type conversion or extraction\n",
    "\n",
    "Before generating a final DataFrame containing the sum of each natural disaster occurrence per country and year, **let's first check to see that their year ranges are consistent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1970', '1971', '1972', '1974', '1975', '1976', '1977', '1978',\n",
       "       '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
       "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994',\n",
       "       '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002',\n",
       "       '2003', '2004', '2005', '2006', '2007', '2008'], dtype=object)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "column_names = []\n",
    "for i in range(len(dfs_nd)):\n",
    "    column_names.append(dfs_nd[i].columns.values)\n",
    "\n",
    "#find years in common\n",
    "reduce(np.intersect1d, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year 1973 is missing from one or more of the DataFrames. After manually scrolling through the previous years, we can see that `df_epidemic` is the one with the missing year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1970', '1971', '1972', '1974'], dtype='object')"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify 1973 does not exist\n",
    "df_epidemic.columns[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MELT DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    pd.melt(df_drought, id_vars = 'country', var_name = 'year', value_name = 'drought_killed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### *OUTER MERGE DATASETS*\n",
    "> **Main idea:** We are using an ***outer merge*** because our data implies that each country in each DataFrame satisfies the following conditions:\n",
    "\n",
    "1) contains reliable non-null data\n",
    "\n",
    "2) represents the true number of its respective natural disaster per year\n",
    "\n",
    "> Consider that we are merging df1 and df2.\n",
    "\n",
    "If df1 contains countries that df2 does not AND df2 contains countries that df1 does not, we want all of those countries to show up in the final result.\n",
    "\n",
    "If df2 contains years that df2 does not AND df2 contains years that df1 does not, we want all of those years to show up in the final result anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *CLASSIFY FREQUENCY AS 'LOW', 'MEDIUM', OR 'HIGH'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obesity Rates\n",
    "> Though generally it may seem that a higher BMI indicates a 'healthier' weight for male, [this article](https://signup.weightwatchers.co.uk/util/art/index_art.aspx?art_id=31901&tabnum=1&sc=803&subnav=Science+Library%3A+Health+and+Weight) clarifies that BMI rates above 25 would still indicate ill health: an equal expectation for both men and women. Based on this fast, I decided it was safe to generate a new CSV, 'bmi_indicator,' for both men and women, by filling each slot with the mean BMI value for men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 'natural_disasters_killed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "# III) Exploring the Data\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "### How much have global obesity rates changed in countries with high forest area vs. countries with low forest area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does a country’s likelihood of experiencing a natural disaster affect the homicidal tendencies of its citizens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "# IV) Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the rubric (found on the project submission page at the end of the lesson). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "## Submitting your Project \n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
